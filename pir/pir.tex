% Fachstudie NEXUS "Personen im Raum"
% $Id: pir.tex,v 1.23 2005/06/22 19:27:56 garbeam Exp $

\documentclass{article}
\usepackage[german]{babel} 
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage[dvips]{graphicx}
\usepackage{url}

\begin{document}

\title{Fachstudie 'Personen im Raum'}
\author{Steffen Keul, Marcel Kilgus, Anselm Garbe\\
\small Universität Stuttgart, Institut für Informatik, Nexus Forschungsprojekt}

\maketitle
\thispagestyle{empty}

\begin{abstract}
In dieser Fachstudie wird die Bewegungserkennung von Personen auf
Bilddaten eines Raumes mithilfe verschiedener Algorithmen aus der
OpenSource Vektor-Grafik Bibliothek OpenCV\cite{opencv} untersucht.
Die Bilddaten werden durch eine handelsübliche Web-Kamera geliefert.
Die Ergebnisse der Bewegungserkennung werden in
Receiver-Operator-Characteristic Curves veranschaulicht. Abschließend
wird die Eignung der untersuchten Algorithmen bewertet.
\end{abstract}

\tableofcontents

%------------------------------------------------------------------------- 
\section{Einleitung}
Im Rahmen des Nexus Forschungsprojektes, das die Realisierung mobiler
kontext-bezogener Systeme in geeigneten Umgebungsmodellen untersucht,
stellt sich u.a. die Aufgabenstellung durch Bilderkennung von Objekten
spezielle kontext-bezogene Reaktionen in solchen Systeme zu realisieren.
Eine einfache Anwendung wäre beispielsweise die akustische Ausgabe einer
Meldung durch ein System, wenn die letzte Person bei geöffnetem
Fenster einen Raum verläßt, das Fenster zu schließen.
Um eine solche Anwendung realisieren zu können muß zunächst ein
geeigneter Weg zur Bilderkennung gefunden werden.


%------------------------------------------------------------------------- 
\section{Ziel}
Ziel dieser Fachstudie ist die Evaluierung der Eignung von folgenden
Bilderkennungs-Algorithmen aus der OpenCV\cite{opencv} Bibliothek:

\begin{itemize}
\item CalcOpticalFlowHS
\item CalcOpticalFlowLK
\item CalcOpticalFlowBM
\item CalcOpticalFlowPyrLK
\item SegmentMotion
\end{itemize}

Es werden Bilddaten eines Raumes einer handelsüblichen Web-Kamera zur
Untersuchung verwendet. Ein Algorithmus, der zuverlässig Bewegungen
auf Bildern erkennt, kann für Aussagen zur
Erkennung von Objekten in Betracht gezogen werden.  Personen sind
keine starren Objekte und zeigen Veränderungen in Form von Bewegungen
zwischen einzelnen Bildern einer Bildsequenz auf.  Die Erkennung
solcher Bewegungen kann zu einer Existenzaussage von Personen im
Bildausschnitt approximiert werden. Darüber stellt sich die Frage, in
wie weit sich solche Existenzaussagen zur Zählung von Personen eignen
und welche Bedingungen sich daran knüpfen.

Neben diesen Bewertungen wird ein kleiner Vergleich auf vorhandene
technische Systeme zur Bewegungserkennung gegeben, die auf Bilderkennung
basieren, sowie ein zur untersuchten Vektor-Grafik-Bibliothek
alternatives Produkt.

%------------------------------------------------------------------------- 
\section{Bilddaten}

Die verwendeten Bilddaten werden mit einer handelsüblichen WebCam,
Modell MOBOTIX M1 (\url{http://www.mobotix.com}), unter identischen
Lichtbedingungen und unverändertem Raumausschnitt erzeugt.  Die
Kameraeinstellungen und Bildeigenschaften sind wie folgt festgelegt:

\begin{figure}[h]
    \begin{center}
        \begin{tabular}{l|l}
        \textbf{Format:} & JPEG\\ \hline
        \textbf{Kompression:} & Standard\\ \hline
        \textbf{Auflösung (Pixel):} & 640x480\\ \hline
        \textbf{Automatischer Lichtfilter:} & aus\\ \hline
        \textbf{Rauschenunterdrückung:} & aus\\ \hline
        \textbf{Hintergrundlicht (-10..10):} & 0\\
        \textbf{Sättigung (-10..10):} & 0\\
        \textbf{Bildschärfe (-2..20):} & 0\\
        \end{tabular}
    {\small \caption{Kameraeinstellungen}}
    \end{center}
\end{figure}

Es werden zur Untersuchung jeweils eine Bildsequenz von 200 Bildern pro
Szenario erstellt.

%------------------------------------------------------------------------- 
\section{Szenarien}
Es werden zwei Szenarien untersucht:

\begin{itemize}
\item keine Person im Bild
\item bewegte Personen im Bild
\end{itemize}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm]{no-probands.ps}
\caption{Keine Person im Bild}
\end{center}
\end{figure}


\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm]{with-probands.ps}
\caption{Personen im Bild}
\end{center}
\end{figure}

Wie in den Bildern dargestellt, befindet sich im ersten Szenario keine
Person im Bildausschnitt aller 200 Bilder. Im anderen Szenario
variiert die Anzahl der Personen. In den folgenden Diagrammen ist die
tatsächliche Anzahl der Personen pro Bild angegeben, die
in der weiteren Untersuchung als Grundlage für die Eignung zur Erkennung
von Personen dient.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-line-no-probands.log.ps}
\caption{Personen pro Bild}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-line-some-probands.log.ps}
\caption{Personen pro Bild}
\end{center}
\end{figure}

%------------------------------------------------------------------------- 
\section{Algorithmen}

\subsection{Optischer Fluss}

OpenCV bietet drei verschiedene Algorithmen zur Berechnung von
optischem Fluss an.  Diese Algorithmen versuchen die Bewegung von
einem Bild zum nächsten zu charakterisieren.  Ergebnis einer solchen
Charakterisierung sind zwei Matrizen, in denen für jeden Pixel aus dem
ersten Bild die Distanz zu seinem entsprechenden Pixel im zweiten Bild
angegeben wird.  In der ersten Matrix Bewegung in horizontaler, in der
zweiten in vertikaler Richtung.

Diese Matrizen allein geben aber noch keine verwertbare Information,
die auf das Nicht-/Vorhandensein von Personen hindeuten könnte.  Die
Bilder, die von den eingesetzten Kameras geliefert werden, enthalten
ein gewisses Maß an Rauschen, d.h. Unterschiede in der Helligkeit
einzelner Pixel der selben Szene.  Dieses Rauschen führt dazu, dass
die OpenCV-Flussalgorithmen für den überwiegenden Anteil der Pixel
eine Bewegung zwischen zwei Bildern feststellen, obwohl die Bilder
nach Ansicht eines menschlichen Beobachters identisch sind.

Ein weiteres wesentliches Problem ist die Wahl der Parameter der
Fluss-Algorithmen.  Für jeden Pixel aus dem ersten Bild wird innerhalb
einer bestimmten Umgebung nach einer Entsprechung im zweiten Bild
gesucht.  Eine große Umgebung hat zwangsläufig negative Auswirkungen
auf die Rechenzeit des Algorithmus, eine kleine Umgebung hingegen kann
nur sehr lokale Bewegungen feststellen.  Eine Person, die sich durch
den Raum bewegt und von einem Bild zum nächsten eine signifikante
Bewegung durchgeführt hat, wird von einem solchen Verfahren nicht
sinnvoll erkannt werden.

Deshalb scheinen reine Flussalgorithmen ohne weiterreichende Analysen
für die Lösung des Problems ungeeignet.  Die Möglichkeiten von OpenCV
werden hier nur der Vollständigkeit halber angegeben.


\subsubsection{CalcOpticalFlowHS}
Dieser Algorithmus berechnet den optischen Bewegungsfluss für alle Pixel
zwischen zwei Bildern nach dem Horn~\&~Schunk \cite{Horn81} Verfahren.

\subsubsection{CalcOpticalFlowLK}
Dieser Algorithmus berechnet den optischen Bewegungsfluss für alle Pixel
zwischen zwei Bildern nach dem Lucas~\&~Kanade \cite{Lucas81} Verfahren.

\subsubsection{CalcOpticalFlowBM}
Dieser Algorithmus berechnet unterteilt die Eingabebilder in Rechtecke
einer bestimmten Größe, sogenannte Basic Blocks.  Der optische Fluss
wird nun statt für einzelne Pixel für diese Basic Blocks berechnet.
In den Ergebnis-Matrizen steht jeweils ein Eintrag für die Distanz in
Anzahl Pixels, die der entsprechende Basic Block aus dem ersten Bild
sich zu seiner Entsprechung im zweiten Bild bewegt hat.

Für die Personen-Erkennung bleibt das Problem, auf welche Weise die
Größe von Basic Blocks gewählt werden soll, und wie tatsächliche
Bewegungen identifiziert werden können.


\subsection{CalcOpticalFlowPyrLK}
\label{pyrlk_algo}
Dieser Algorithmus \cite{Bouget00} basiert auf einer iterativen
Version der optischen Fluss-Pyramiden nach Lucas~\&~Kanade.  Hierbei
werden die beiden Eingabe-Bilder nach einem bestimmten Verfahren
sukzessive um Faktor 4 verkleinert.  So entstehen zwei Pyramiden von
Bildern.  Die untersten Ebenen dieser Pyramiden sind die
Eingabe-Bilder.  Die weiteren Ebenen ihre Verkleinerungen.  Dann wird
mit dem Verfahren nach Lucas~\&~Kanade der optische Fluss zwischen den
einander entsprechenden Ebenen dieser Pyramiden berechnet, beginnend
an der Spitze der Pyramide.  Das Ergebnis einer Ebene wird als
Vermutung für die Berechnung des Flusses in der nächst größeren Ebene
verwendet.  Auf diese Weise kann dieser Algorithmus sowohl sehr lokale
Bewegungen wie auch Bewegungen, die einen großen Ausschnitt des Bildes
betreffen zuverlässig erkennen.

Somit liefert dieser Algorithmus einen optischen Fluss, der näher an
der gewünschten Information liegt.  Trotzdem besteht noch das gleiche
Problem wie mit den anderen Fluss-Algorithmen, nämlich die Frage, wie
optischer Fluss überhaupt zur Erkennung von Personen eingesetzt werden
kann.

Hierzu liefert OpenCV jedoch eine Antwort, da die Funktion
CalcOpticalFlowPyrLK Funktionalität zum Feature-Tracking mit umfasst.
Der optische Fluss wird verwendet, um die Bewegung einer Menge von
Feature-Points im ersten Bild zu den entsprechenden Positionen im
zweiten Bild zu berechnen.  Feature-Points können durch einen weiteren
Algorithmus automatisch für ein Bild berechnet werden.

Bei automatischer Berechnung der Feature-Points bleibt allerdings
unklar, welche Information sich aus dem Verfolgen dieser Punkte
tatsächlich gewinnen lässt.  Insbesondere ist unklar, wie
sichergestellt wird, dass evtl. im Raum befindliche Personen
tatsächlich von diesen Feature-Points erfasst werden.

In praktischen Tests wurde festgestellt, dass der Algorithmus dazu
neigt, Feature-Points mit der Zeit zu verlieren, dh. im zweiten Bild
gar nicht wieder zu finden.  Insbesondere wenn Objekte durch andere
verdeckt werden, tritt dieser Effekt ein.  Deshalb wird von Zeit zu
Zeit eine Neuberechnung der Feature-Points notwendig.  Durch diese
Neuberechnung geht natürlich Information über die aktuelle Szene
verloren.

Für das Personen im Raum-Problem erschien es sinnvoll, eine feste
Menge von Feature-Points vorzugeben, die an geeigneten Stellen im Bild
strategisch platziert werden.  Jede Person, die den Raum betritt oder
verlässt, wird eine Bewegung der Eingangstür verursachen, genau so wie
Personen, die an einem bestimmten Arbeitsplatz sitzen eben dort
Bewegungen verursachen.



\subsection{SegmentMotion}
\label{segmentmotion_algo}
Mit Hilfe des SegmentMotion-Algorithmus aus OpenCV lassen sich
Bewegungen die von einem Bild zum nächsten aufgetreten sind, in
einzelne Teilbewegungen zerlegen.  Gehen also zwei Personen in
verschiedenen Teilen des Raumes umher, so soll SegmentMotion die
Bewegungen der beiden Personen in getrennte Bewegungen zweier
verschiedener Objekte unterteilen können.

Durch die Teilung in einzelne Objekte wird es möglich, Abschätzungen
über die Heftigkeit einer Bewegung oder die Größe des bewegten Objekts
zu machen.  Beides sind wertvolle Indizien, falls entschieden werden
soll, ob die Detektierung einer Bewegung im Bild durch eine Person
oder nur durch eine Veränderung in den Lichtverhältnissen im Bild
hervorgerufen wurde.

Die OpenCV-Implementierung von SegmentMotion wird angewendet auf eine
Motion~History.  Motion~History ist eine Matrix in der Größe der
Eingabebilder, in der in jeder Zelle ein Zeitstempel eingetragen wird.
Dieser Zeitstempel gibt den letzten Zeitpunkt an, an dem zuletzt eine
Bewegung dieses Pixels erkannt wurde.  Durch Verwendung der
Motion~History wird es somit möglich, das Verschwinden einer Bewegung
künstlich um eine konfigurierbare Zeit zu verzögern.  Dies
ermöglicht auch sehr kurz andauernde aber häufig auftretende
Bewegungen sicher zu erkennen.

Die Einträge in eine Motion~History schließlich werden anhand eines
Differenzbildes erstellt.  Zwei Bilder werden zu Graustufen
umgewandelt und an jedem Koordinatenpunkt wird die Differenz der
Helligkeit der entsprechenden Punkte berechnet.  Ist die Differenz
größer als ein bestimmter Schwellwert, so wird an diesem Punkt eine
Bewegung vermutet.  Die Punkte mit vermuteten Bewegungen werden in die
Motion~History aufgenommen.  Mittels SegmentMotion werden Bewegungen
einzelner Objekte extrahiert und solche Objekte, die extrem klein sind,
werden unmittelbar verworfen, da sie mit großer Wahrscheinlichkeit auf
Rauschen zurückzuführen sind.

Ein Vorteil dieses Verfahrens gegenüber dem
CalcOpticalFlowPyrLK-Algorithmus liegt deutlich in der kürzeren
Ausführungszeit.  Auch fällt die Problematik der Feature-Point
Berechnung weg.  Der Algorithmus ist problemlos für alle Räume
anwendbar.  Schwierig ist jedoch die Justierung der Parameter
(Schwellwert für Bewegungserkennung, minimale Objektgröße, maximale
History-Dauer).



\subsection{Eigene Implementierung}
Neben den genannten Algorithmen aus der Vektor-Grafik-Bibliothek
OpenCV\cite{opencv} wurde auch ein eigener Algorithmus entworfen und
untersucht, der erst versucht mit Hilfe von Schwellwerten das Bildrauschen
zu minimieren und danach das Bild in Segmente einteilt, für die jeweils 
die Zahl geänderten Pixel ermittelt wird. Liegt diese über einer bestimmten
Schwelle wird eine Bewegung im Segment angenommen und entsprechend 
visuell im Differenzbild dargstellt.



%------------------------------------------------------------------------- 
\section{Vorgehen}

OpenCV ist eine Bibliothek, die Bausteine (Funktionen) zur
Bildverarbeitung bereitstellt.  Zusätzlich werden einige
Beispielprogramme angeboten, die Möglichkeiten von der Algorithmen in
OpenCV erläutern sollen und die intendierte Verwendung von OpenCV
illustrieren.

Im Rahmen dieser Fachstudie sollte keine neue Technologie entwickelt
werden, sondern vorhandene Möglichkeiten der OpenCV Bibliothek
evaluiert werden.  Deshalb wurden zur Untersuchung die
Beispielprogramme von OpenCV herangezogen und soweit erweitert, dass
verwertbare Messergebnisse produziert werden.  Die Semantik der
untersuchten Verfahren wurde nach Überzeugung der Autoren
nicht verändert.

\subsection{Grundlagen}

Insgesamt wurden drei Testprogramme untersucht.  In allen
Testprogrammen können Parameterwerte der Algorithmen über
Kommandozeilen-Parameter eingestellt werden.  Mit dem Parameter
\emph{help} kann eine Liste der angebotenen Parameter ausgegeben
werden.  Falls ein Testprogramm mit dem Parameter \emph{visualize}
gestartet wird, so zeigt es mit Hilfe der OpenCV-Funktionen dynamisch
die Ergebnisse grafisch an.

Alle Testprogramme schreiben zusätzlich Ausgabe auf die
Standard-Ausgabe.  Diese Ausgabe besteht aus einem Datensatz pro
analysiertem Bild.  Jeder Datensatz hat die Form

\begin{verbatim}
image_12345.33343.png   2   0.230000
\end{verbatim}

In der ersten Spalte steht der Name des Bildes, in der zweiten die
Anzahl der erkannten Bewegungen, in der dritten die Rechenzeit in
Sekunden.  Diese Ausgabe lässt sich automatisiert mit einer
Referenzausgabe vergleichen.


\subsection{Referenzausgabe}

Um Tests durchführen zu können wurde das Programm manual.c
implementiert.  Es zeigt dem Benutzer Bild für Bild die untersuchte
Bildersequenz an und erwartet als Eingabe die Zahl der vom Benutzer
gesehen Personen auf dem Bild.  Das Programm produziert daraufhin die
gleiche Ausgabe wie die Testprogramme und schafft somit eine
Referenzausgabe, mit der die Ausgaben der Testprogramme verglichen
werden können.


\subsection{CalcOpticalFlowPyrLK}

Der in Abschnitt \ref{pyrlk_algo} beschriebene Algorithmus wird von
dem Beispielprogramm lkdemo.c implementiert.  Allerdings verwendet
dieses Beispiel automatische Suche nach geeigneten Feature-Points.
Diese musste ersetzt werden durch die beschriebene vordefinierte Liste
von Feature-Points.  Das Ergebnis ist das Programm pyramid.c es
akzeptiert als Parameter die Datei mit Feature-Point Koordinaten sowie
einen Schwellwert, ab dem eine Bewegung von Feature-Points als reale
Bewegung im Bild interpretiert wird.

Um mehrere Bewegungen zählen zu können, wird die Menge der
Feature-Points in einzelne Feature-Point Gruppen unterteilt.  Für
jedes Bild der untersuchten Sequenz wird jede Gruppe gezählt, in der
eine Bewegung stattgefunden hat.  Davon erhoffen sich die Autoren eine
Personenzählung approximieren zu können.

Die Feature-Point Dateien werden mit dem Programm setfeature.c
erstellt.  Dieses Programm musste als Hilfsmittel für die Durchführung
des Tests erstellt werden und ist von OpenCV bis auf die Verwendung
von Datenstrukturen unabhängig.


\subsection{Segment Motion}

Der in Abschnitt \ref{segmentmotion_algo} beschriebene Algorithmus
wird von dem Beispielprogramm motempl.c implementiert.  Dieser
Beispielcode wurde als Vorlage für das Testprogramm motion.c
verwendet.  Als Parameter können die Dauer der Motion~History, die
Anzahl der gepufferten Bilder und ein Bereich reeller Zahlen
angegeben werden, in dem sich Gradienten der Motion~History befinden
müssen.  Dieser Algorithmus interpretiert den Namen der Eingabebilder,
um den Zeitpunkt ihrer Aufnahme festzustellen.


%------------------------------------------------------------------------- 
\section{Untersuchung}

Die drei unterschiedlichen Algorithmen-Arten wurden parametrisiert auf
die jeweils 200 Bilder pro Szenario angewendet. Dabei wurde pro
Bild von dem jeweiligen Algorithmus die Anzahl der erkannten
Personen (Bewegungsfelder) ausgegeben, die in den Diagrammen im Anhang
im Detail angegeben ist.

\subsection{Eigene Implementierung}

Aufgrund der Uneignung der Algorithmen CalcOpticalFlowHS,
CalcOpticalFlowLK und CalcOpticalFlowBM, die lediglich Richtungsvektoren
von bewegten Pixeln berechnen, wurde die eigene Implementierung
auf beiden Szenarien angewendet und untersucht.
Die Güte und Zuverlässigkeit des eigenen Algorithmus wurde in Beziehung zu den
tatsächlichen Personen im Bild in eine absolute Erkennungsrate
umgerechnet, die wie folgt pro Szenario ausgefallen ist.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-optical-flow-1.log.ps}
\caption{Erkennungsrate, erstes Szenario, Eigene Implementierung}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-optical-flow-2.log.ps}
\caption{Erkennungsrate, zweites Szenario, Eigene Implementierung}
\end{center}
\end{figure}

Aus den Erkennunsgraten ist ersichtlich, dass die eigene
Implementierung keine Falsch-Positiv Treffer im ersten Szenario
detektiert haben. Die recht gute Kurve im zweiten Szenario deutet allerdings
auf eine Ungenauigkeit zur Zählung von Personen hin.
Die eigene Implementierung kann also lediglich zur Existenzaussage
von Bewegungen in Betracht gezogen werden, für diese Aussagen ist sie
sehr schnell und sehr zuverlässig.


\subsection{Segment Motion}

Der SegementMotion Algorithmus der OpenCV\cite{opencv} Bibliothek bietet
verschiedene Schalter zur Parametrisierung an. Getestet wurden folgende
Parametrisierungen auf jeweils beiden Szenarien, deren Ergebnisse in
Diagrammen im Anhang ersichtlich sind.

\begin{figure}[h!]
    \begin{center}
        \begin{tabular}{c|c|c|c|c}
        \textbf{Durchlauf} & \textbf{History} & \textbf{Buffer} & \textbf{Min-Time-Delta} & \textbf{Max-Time-Delta}\\ \hline
        1 & 1s & 2 & 0.05 & 0.5\\ \hline
        2 & 2s & 2 & 0.05 & 0.5\\ \hline
        3 & 3s & 2 & 0.05 & 0.5\\ \hline
        4 & 5s & 2 & 0.05 & 0.5\\ \hline
        5 & 10s & 2 & 0.05 & 0.5\\ \hline
        6& 1s & 2 & 0.001 & 1.0\\ \hline
        7& 2s & 2 & 0.001 & 1.0\\ \hline
        8& 3s & 2 & 0.001 & 1.0\\ \hline
        9& 5s & 2 & 0.001 & 1.0\\ \hline
        10& 10s & 2 & 0.001 & 1.0\\ \hline
        11& 1s & 2 & 0.001 & 3.0\\ \hline
        12& 2s & 2 & 0.001 & 3.0\\ \hline
        13& 3s & 2 & 0.001 & 3.0\\ \hline
        14& 5s & 2 & 0.001 & 3.0\\ \hline
        15& 10s & 2 & 0.001 & 3.0\\ \hline
        \end{tabular}
    {\small \caption{Parametrisierung von SegmentMotion}}
    \end{center}
\end{figure}

Die Ausführung des SegmentMotion Algorithmus hat vor allem signifikante
Unterschiede beim Parameter des History-Puffers gezeigt. Ein Wert von
$1s$ kann als zu gering, ein Wert von $10s$ wiederum als zu hoch
angesehen werden. Die Time-Delta Werte haben bei der Ausführung nahezu
keine Auswirkung gezeigt, da die von der WebCam aufgezeichneten
Bilddaten einen niedrigen Durchsatz pro Sekunde liefern (im Mittel
etwa 1.5 Bilder pro Sekunde).
Der Bildpuffer (Buffer) Parameter hat auch keine signifikante
Auswirkung bei den verwendeten Bildern geliefert. Ein größerer Puffer
kann die Ausführungsgeschwindigkeit reduzieren.

Die besten Resultate wurden mit History-Werten von $3s$ bzw. $5s$
geliefert. Im folgenden ist die Erkennungsrate aus Durchlauf 9
dargestellt - auf die jeweilige Sequenz angewendet.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-motion-1.log.ps}
\caption{Erkennungsrate, erstes Szenario, SegmentMotion}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-motion-2.log.ps}
\caption{Erkennungsrate, zweites Szenario, SegmentMotion}
\end{center}
\end{figure}

Dar"uber hinaus wurde die Receiver-Operator-Characteristic Curve
zur Veranschaulichung der G"ute aller Durchl"aufe (beide Szenarien
zusammengefasst) erstellt.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-motion.ps}
\caption{ROC, SegmentMotion}
\end{center}
\end{figure}

Wie aus den Erkennungsraten (siehe auch Diagramme im Anhang) ersichtlich, liefert
der SegmentMotion Algorithmus nahezo keine Falsch-Positiv Treffer im ersten
Szenario. Im zweiten Szenario werden Bewegungen erkannt, diese eignen
sich aber nicht zur Zählung von Personen. SegmentMotion hat bei
Bewegungen deutlich mehr Falsch-Positiv Treffer geliefert, d.h. es
wurden im Mittel deutlich mehr Personen erkannt, als tatsächlich
vorhanden. Deutlich ist allerdings, das sich SegmentMotion zur
Existenzaussage von Bewegungen sehr gut eignet.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/motion_1.ps}
\caption{Zweites Szenario, SegmentMotion, Korrekte Erkennung}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/motion_2.ps}
\caption{Zweites Szenario, SegmentMotion, Proband im Vordergrund wird
  nicht erkannt, da er still sitzt}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/motion_3.ps}
\caption{Zweites Szenario, SegmentMotion, Erkennung zu vieler
  Bewegungen}
\end{center}
\end{figure}

\subsection{CalcOpticalFlowPyrLK}

Der CalcOpticalFlowPyrLK Algorithmus der OpenCV\cite{opencv} Bibliothek
bietet als besonderen Parameter Feature-Points an, die eine
Bewegungserkennung in ausgewählten Bildbereichen detektieren können.
Da die Bilder jedoch keine Tiefeninformation bieten, ist
eine eindeutige Aussage, ob eine Bewegung im Bereich des gesetzten
Feature-Points für das menschliche Auge stattgefunden hat, nicht möglich.
Letzterer Fall kann eintreten, wenn beispielsweise eine Fliege vor der Linse
der WebCam ihr Unwesen treibt, der Feature-Point aber im Regelfall 8m
vom Kameraobjektiv entfernt ist.

Neben den Feature-Points kann man den CalcOpticalFlowPyrLK Algorithmus
noch mit einem Unschärfewert (Threshold) parametrisieren. Für die
Untersuchung wurden zwei Mengen von Feature-Points und verschiedene
Unschärfewerte auf beide Szenarien angewendet:

\begin{figure}[h]
    \begin{center}
        \begin{tabular}{c|c|c}
        \textbf{Durchlauf} & \textbf{Feature-Points} & \textbf{Threshold}\\ \hline
        1 & I & 1.0\\ \hline
        2 & II & 1.0\\ \hline
        3 & I & 0.5\\ \hline
        4 & II & 0.5\\ \hline
        5 & I & 5.0\\ \hline
        6 & II & 5.0\\ \hline
        7 & I & 10.0\\ \hline
        8 & II & 10.0\\ \hline
        \end{tabular}
    {\small \caption{Parametrisierung von SegmentMotion}}
    \end{center}
\end{figure}

Die besten Resultate lieferte ein möglichst hoher Unschärfewert. Die
Feature-Points haben auf den vorliegenden Bildern eher keine positive
Auswirkung zeigen können, da der Winkel der Kamera zu flach ist, um
Bewegungen im hinteren Raumbereich von Bewegungen in Kameranähe
unterscheiden zu können.
Unter den Umständen der gegebenen Daten und Kameraeinstellung lieferte
der CalcOpticalFlowPyrLK die mit Abstand schlechtesten Resultate, wie
aus den Diagrammen im Anhang ersichtlich ist. Wenn die Kamera
z.B. an der Raumdecke angebracht wäre, könnte der Algorithmus
vermutlich sehr gute Resultate liefern, da dann Bewegungen von oben
bestimmten Raumbereichen im Regelfall eindeutig zugeordnet werden
könnten.

Die beide Szenarien zusammenfassende Receiver-Operator-Characteristic
Curve zur Veranschaulichung der G"ute von CalcOpticalFlowPyrLK unter den
untersuchten Bedingungen ist im folgenden Diagramm ersichtlich.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-pyramid.ps}
\caption{ROC, CalcOpticalFlowPyrLK}
\end{center}
\end{figure}

Die Erkennungsraten zum 7. Durchlauf, der die besten Ergebnisse
lieferte, sind wie folgt veranschaulicht.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-pyramid-1.log.ps}
\caption{Erkennungsraten, erstes Szenario, CalcOpticalFlowPyrLK}
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/roc-pyramid-2.log.ps}
\caption{Erkennungsraten, zweites Szenario, CalcOpticalFlowPyrLK}
\end{center}
\end{figure}

Im ersten Szenario detektierte CalcOpticalFlowPyrLK Falsch-Positive
Treffer, die vermutlich auf das Bild-Rauschen zurückzuführen sind. Im
zweiten Szenario liegt CalcOpticalFlowPyrLK von der korrekten Erkennung
der tatsächlichen Personen sogar unterhalb der Zufalls-Charakteristik
und ist damit als schlechter einzustufen, als die Personenerkennung
durch einen Zufallsgenerator durchzuführen.

Allerdings ist zu berücksichtigen, das CalcOpticalFlowPyrLK
diese Resultate bei idealeren Bedingungen nicht zutreffen müssen.

\begin{center}
\begin{figure}
\includegraphics[width=7cm,angle=270]{impl/features_1_1.ps}
\caption{Zweites Szenario, CalcOpticalFlowPyrLK, Feature-Point Menge
  1, unerwünschte Mehrfacherkennung der selben Bewegung}
\end{figure}

\begin{figure}
\includegraphics[width=7cm,angle=270]{impl/features_1_2.ps}
\caption{Zweites Szenario, CalcOpticalFlowPyrLK, Feature-Point Menge 1, Günstige Verteilung der Bewegungen im Raum}
\end{figure}

\begin{figure}
\includegraphics[width=7cm,angle=270]{impl/features_1_3.ps}
\caption{Zweites Szenario, CalcOpticalFlowPyrLK, Feature-Point Menge 1, Ungenauigkeit des Verfahrens führt zu Fehlerkennungen}
\end{figure}
\end{center}



%------------------------------------------------------------------------- 
\subsection{Alternativen}

Neben der in dieser Fachstudie untersuchten OpenCV\cite{opencv}
Bibliothek existieren viele andere Produkte auf dem IT-Markt, die
Produkte zum Thema ``Optischer Fluss'' anbieten.

\subsubsection{WebCam}
Selbst die verwendete Kamera, Modell MOBOTIX M1 (\url{http://www.mobotix.com}),
bietet von sich aus Tracking-Algorithmen an, die den optischen Fluss der einzelnen
Bilder berücksichtigen und bewegte Bereiche verfolgen und
grafisch hervorheben können. Diese Hervorhebungen können in der
Kamerasteuerung als Auslöser für Ereignisse verwendet werden.
Die Kamera enthält neben Algorithmen zur Bilderkennung aber auch
herkömmliche Bewegungssensoren, die aufgrund von Wärme-Detektion bzw.
Elektro-Magnetfeld-Analyse Bewegungen registriert, die zur
Ereignisauslösung herangezogen werden können.

\subsubsection{MontiVision Development Kit}
Für das Windows Betriebssystem bietet die Firma MontiVision ein
OpticalFlow Modul\cite{montivision} an, das in ihrem Development Kit zur
Analyse von optischen Flüssen von Eingabedaten verwendet werden kann.
Neben einer eigentlichen API bietet dieses Development Kit auch eine
grafische Oberfläche, die in Form von Daten-Strom-Grafen, ähnlich einer
Pipe-Filter Architektur, es dem Anwender sehr einfach ermöglicht,
verschiedene optische Fluss-Filter sequentiell
hintereinanderzuschalten. Am Anfang solcher Verkettungen wird eine
Datenquelle angegeben. Wenn so eine Konfiguration ausgeführt
wird, kann der Anwender das Resultat der Filter auf den Eingabe-Daten
grafisch mitverfolgen, z.B. werden bewegte Bereiche grafisch
hervorgehoben.

%------------------------------------------------------------------------- 
\section{Fazit}
Im Rahmen dieser Fachstudie haben wir festgestellt, das die genannten
Algorithmen sich zur Existenzaussage von Bewegungen in Bildern eignen,
jedoch zur Zählung von Personen nur bedingt geeignet sind. Die effizienteste
Ausführung zur Existenzaussage von Bewegungen in einem Bildausschnitt
liefert die eigene Implementierung. Qualitativ ähnliche Resultate zur
eigenen Implementierung liefert der SegmentMotion Algorithmus aus der
OpenCV Bibliothek.

Eine auf den genannten Ergebnissen aufbauende Implementierung könnte
beispielsweise noch Gesichtserkennungsalgorithmen und Stereo-Bilder in
Betracht ziehen, um eine Personenzählung durch Bilderkennung
zuverlässiger zu ermöglichen.

\begin{thebibliography}{99}
\bibitem{opencv} http://opencvlibrary.sf.net
\bibitem{Horn81} Berthold K. P. Horn und Brian G. Schunck. Determining
Optical Flow. Artificial Intelligence, 17, pp. 185-203, 1981.
\bibitem{Lucas81} Lucas, B. und Kanade, T. An Iterative Image
Registration Technique with an Application to Stereo Vision, Proc. of
7th International Joint Conference on Artificial Intelligence (IJCAI),
pp. 674-679.
\bibitem{Bouget00} Jean-Yves Bouguet. Pyramidal Implementation of the
Lucas Kanade Feature Tracker.
\bibitem{montivision} MontiVision Development Kit, OpticalFlow Modul,
http://www.montivision.com/support/documentation/noframes/source/filter/optical\_flow\_filter.htm
\end{thebibliography}

\section*{Anhang}

\subsection*{Feature-Points I}
Die Feature-Points sind (x y) Paare an absoluten Pixel-Positionen.
Einzelne Points sind durch Kommata getrennt, Feature-Point Gruppen
durch Semikolons.


\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/feature_point_image1.ps}
\caption{Feature-Points I}
\end{center}
\end{figure}

\begin{verbatim}
(167.000000 367.000000),(188.000000 367.000000),(213.000000
371.000000),(247.000000 367.000000),(271.000000 367.000000),(278.000000
392.000000),(249.000000 396.000000),(222.000000 401.000000),(197.000000
401.000000),(169.000000 403.000000),(166.000000 436.000000),(193.000000
436.000000),(217.000000 435.000000),(248.000000 435.000000),(272.000000
436.000000),(295.000000 441.000000),(300.000000 461.000000),(267.000000
466.000000),(244.000000 466.000000),(214.000000 466.000000),(186.000000
467.000000),(168.000000 467.000000),(142.000000 468.000000),(143.000000
440.000000),(308.000000 410.000000),(305.000000 377.000000);(382.000000
311.000000),(383.000000 327.000000),(380.000000 346.000000),(377.000000
367.000000),(378.000000 382.000000),(376.000000 399.000000),(376.000000
413.000000),(378.000000 426.000000),(379.000000 448.000000),(402.000000
450.000000),(430.000000 449.000000),(444.000000 448.000000),(468.000000
443.000000),(489.000000 443.000000),(489.000000 422.000000),(485.000000
401.000000),(483.000000 381.000000),(482.000000 364.000000),(481.000000
345.000000),(480.000000 316.000000),(481.000000 299.000000),(482.000000
279.000000),(492.000000 345.000000),(468.000000 347.000000),(399.000000
339.000000),(413.000000 341.000000),(430.000000 342.000000),(448.000000
342.000000),(458.000000 367.000000),(436.000000 393.000000),(413.000000
423.000000),(404.000000 368.000000),(459.000000 409.000000);(461.000000
217.000000),(478.000000 217.000000),(494.000000 217.000000),(517.000000
218.000000),(534.000000 217.000000),(557.000000 216.000000),(553.000000
237.000000),(555.000000 259.000000),(534.000000 260.000000),(532.000000
240.000000),(436.000000 219.000000),(432.000000 231.000000),(432.000000
246.000000),(449.000000 226.000000),(468.000000 227.000000),(486.000000
226.000000),(502.000000 225.000000),(543.000000 200.000000),(539.000000
185.000000),(546.000000 229.000000),(524.000000 271.000000),(521.000000
252.000000);(156.000000 236.000000),(177.000000 236.000000),(201.000000
236.000000),(224.000000 238.000000),(225.000000 254.000000),(225.000000
271.000000),(224.000000 288.000000),(223.000000 303.000000),(245.000000
299.000000),(241.000000 307.000000),(232.000000 315.000000),(223.000000
321.000000),(207.000000 319.000000),(184.000000 317.000000),(173.000000
317.000000),(160.000000 317.000000),(144.000000 316.000000),(132.000000
331.000000),(132.000000 351.000000),(116.000000 323.000000),(123.000000
305.000000),(133.000000 286.000000),(146.000000 263.000000),(159.000000
282.000000),(180.000000 295.000000),(202.000000 297.000000),(208.000000
277.000000),(191.000000 261.000000),(169.000000 262.000000),(210.000000
261.000000),(244.000000 265.000000),(244.000000 285.000000),(245.000000
299.000000),(257.000000 243.000000),(274.000000 232.000000),(256.000000
222.000000),(240.000000 232.000000),(223.000000 220.000000),(186.000000
220.000000),(205.000000 220.000000);(299.000000 173.000000),(298.000000
186.000000),(296.000000 217.000000),(299.000000 240.000000),(306.000000
258.000000),(327.000000 260.000000),(342.000000 260.000000),(355.000000
243.000000),(362.000000 221.000000),(375.000000 213.000000),(383.000000
203.000000),(385.000000 189.000000),(386.000000 167.000000),(371.000000
159.000000),(356.000000 164.000000),(354.000000 181.000000),(369.000000
179.000000),(367.000000 196.000000),(340.000000 210.000000),(314.000000
194.000000),(311.000000 170.000000),(331.000000 173.000000),(319.000000
224.000000),(311.000000 206.000000),(293.000000 199.000000),(329.000000
193.000000),(343.000000 194.000000),(333.000000 158.000000),(315.000000
179.000000),(343.000000 224.000000),(359.000000 208.000000),(331.000000
240.000000);(523.000000 162.000000),(512.000000 161.000000),(497.000000
162.000000),(553.000000 146.000000),(568.000000 144.000000),(581.000000
152.000000),(588.000000 166.000000),(534.000000 156.000000),(552.000000
136.000000),(564.000000 128.000000),(561.000000 139.000000),(505.000000
151.000000),(503.000000 139.000000),(505.000000 125.000000),(517.000000
119.000000),(529.000000 119.000000),(538.000000 119.000000),(550.000000
120.000000),(450.000000 188.000000),(465.000000 187.000000),(470.000000
164.000000),(458.000000 166.000000),(438.000000 162.000000),(435.000000
147.000000),(447.000000 133.000000),(449.000000 120.000000),(432.000000
124.000000),(429.000000 138.000000),(424.000000 147.000000),(415.000000
163.000000),(397.000000 155.000000),(384.000000 160.000000),(409.000000
148.000000),(392.000000 133.000000),(384.000000 147.000000),(409.000000
133.000000),(419.000000 184.000000),(428.000000 193.000000);(39.000000
176.000000),(34.000000 200.000000),(40.000000 226.000000),(34.000000
247.000000),(36.000000 265.000000),(39.000000 292.000000),(36.000000
317.000000),(34.000000 344.000000),(30.000000 357.000000),(28.000000
374.000000),(27.000000 390.000000),(25.000000 422.000000),(23.000000
445.000000),(44.000000 456.000000),(65.000000 460.000000),(92.000000
461.000000),(124.000000 461.000000),(120.000000 442.000000),(121.000000
420.000000),(120.000000 400.000000),(115.000000 381.000000),(113.000000
350.000000),(109.000000 322.000000),(108.000000 305.000000),(111.000000
271.000000),(110.000000 249.000000),(111.000000 215.000000),(109.000000
181.000000),(108.000000 152.000000),(110.000000 197.000000),(40.000000
151.000000),(60.000000 136.000000),(85.000000 142.000000),(72.000000
421.000000),(72.000000 400.000000),(71.000000 371.000000),(73.000000
344.000000),(74.000000 203.000000),(73.000000 228.000000),(71.000000
264.000000);(9.000000 121.000000),(22.000000 120.000000),(38.000000
117.000000),(54.000000 116.000000),(67.000000 113.000000),(84.000000
113.000000),(98.000000 110.000000),(118.000000 106.000000),(132.000000
104.000000),(150.000000 102.000000),(168.000000 97.000000),(185.000000
95.000000),(275.000000 78.000000),(288.000000 75.000000),(300.000000
71.000000),(315.000000 65.000000),(327.000000 77.000000),(327.000000
93.000000),(329.000000 105.000000),(329.000000 116.000000),(330.000000
128.000000),(332.000000 140.000000),(343.000000 142.000000),(355.000000
144.000000),(369.000000 141.000000),(376.000000 123.000000),(391.000000
117.000000),(423.000000 97.000000),(406.000000 107.000000),(441.000000
82.000000),(453.000000 66.000000),(507.000000 104.000000),(526.000000
89.000000),(543.000000 78.000000),(558.000000 65.000000),(577.000000
54.000000),(581.000000 103.000000),(564.000000 93.000000),(515.000000
64.000000),(458.000000 106.000000).
\end{verbatim}


\subsection*{Feature-Points II}
Die Feature-Points sind (x y) Paare an absoluten Pixel-Positionen.
Einzelne Points sind durch Kommata getrennt, Gruppen von Points durch
Semikolons.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=7cm,angle=270]{impl/feature_point_image2.ps}
\caption{Feature-Points II}
\end{center}
\end{figure}

\begin{verbatim}
(167.000000 367.000000),(188.000000 367.000000),(213.000000
371.000000),(247.000000 367.000000),(271.000000 367.000000),(278.000000
392.000000),(249.000000 396.000000),(222.000000 401.000000),(197.000000
401.000000),(169.000000 403.000000),(166.000000 436.000000),(193.000000
436.000000),(217.000000 435.000000),(248.000000 435.000000),(272.000000
436.000000),(295.000000 441.000000),(300.000000 461.000000),(267.000000
466.000000),(244.000000 466.000000),(214.000000 466.000000),(186.000000
467.000000),(168.000000 467.000000),(142.000000 468.000000),(143.000000
440.000000),(308.000000 410.000000),(305.000000 377.000000);(382.000000
311.000000),(383.000000 327.000000),(380.000000 346.000000),(377.000000
367.000000),(378.000000 382.000000),(376.000000 399.000000),(376.000000
413.000000),(378.000000 426.000000),(379.000000 448.000000),(402.000000
450.000000),(430.000000 449.000000),(444.000000 448.000000),(468.000000
443.000000),(489.000000 443.000000),(489.000000 422.000000),(485.000000
401.000000),(483.000000 381.000000),(482.000000 364.000000),(481.000000
345.000000),(480.000000 316.000000),(481.000000 299.000000),(482.000000
279.000000),(492.000000 345.000000),(468.000000 347.000000),(399.000000
339.000000),(413.000000 341.000000),(430.000000 342.000000),(448.000000
342.000000),(458.000000 367.000000),(436.000000 393.000000),(413.000000
423.000000),(404.000000 368.000000),(459.000000 409.000000);(461.000000
217.000000),(478.000000 217.000000),(494.000000 217.000000),(517.000000
218.000000),(534.000000 217.000000),(557.000000 216.000000),(553.000000
237.000000),(555.000000 259.000000),(534.000000 260.000000),(532.000000
240.000000),(436.000000 219.000000),(432.000000 231.000000),(432.000000
246.000000),(449.000000 226.000000),(468.000000 227.000000),(486.000000
226.000000),(502.000000 225.000000),(543.000000 200.000000),(539.000000
185.000000),(546.000000 229.000000),(524.000000 271.000000),(521.000000
252.000000);(156.000000 236.000000),(177.000000 236.000000),(201.000000
236.000000),(224.000000 238.000000),(225.000000 254.000000),(225.000000
271.000000),(224.000000 288.000000),(223.000000 303.000000),(245.000000
299.000000),(241.000000 307.000000),(232.000000 315.000000),(223.000000
321.000000),(207.000000 319.000000),(184.000000 317.000000),(173.000000
317.000000),(160.000000 317.000000),(144.000000 316.000000),(132.000000
331.000000),(132.000000 351.000000),(116.000000 323.000000),(123.000000
305.000000),(133.000000 286.000000),(146.000000 263.000000),(159.000000
282.000000),(180.000000 295.000000),(202.000000 297.000000),(208.000000
277.000000),(191.000000 261.000000),(169.000000 262.000000),(210.000000
261.000000),(244.000000 265.000000),(244.000000 285.000000),(245.000000
299.000000),(257.000000 243.000000),(274.000000 232.000000),(256.000000
222.000000),(240.000000 232.000000),(223.000000 220.000000),(186.000000
220.000000),(205.000000 220.000000);(299.000000 173.000000),(298.000000
186.000000),(296.000000 217.000000),(299.000000 240.000000),(306.000000
258.000000),(327.000000 260.000000),(342.000000 260.000000),(355.000000
243.000000),(362.000000 221.000000),(375.000000 213.000000),(383.000000
203.000000),(385.000000 189.000000),(386.000000 167.000000),(371.000000
159.000000),(356.000000 164.000000),(354.000000 181.000000),(369.000000
179.000000),(367.000000 196.000000),(340.000000 210.000000),(314.000000
194.000000),(311.000000 170.000000),(331.000000 173.000000),(319.000000
224.000000),(311.000000 206.000000),(293.000000 199.000000),(329.000000
193.000000),(343.000000 194.000000),(333.000000 158.000000),(315.000000
179.000000),(343.000000 224.000000),(359.000000 208.000000),(331.000000
240.000000);(523.000000 162.000000),(512.000000 161.000000),(497.000000
162.000000),(553.000000 146.000000),(568.000000 144.000000),(581.000000
152.000000),(588.000000 166.000000),(534.000000 156.000000),(552.000000
136.000000),(564.000000 128.000000),(561.000000 139.000000),(505.000000
151.000000),(503.000000 139.000000),(505.000000 125.000000),(517.000000
119.000000),(529.000000 119.000000),(538.000000 119.000000),(550.000000
120.000000),(450.000000 188.000000),(465.000000 187.000000),(470.000000
164.000000),(458.000000 166.000000),(438.000000 162.000000),(435.000000
147.000000),(447.000000 133.000000),(449.000000 120.000000),(432.000000
124.000000),(429.000000 138.000000),(424.000000 147.000000),(415.000000
163.000000),(397.000000 155.000000),(384.000000 160.000000),(409.000000
148.000000),(392.000000 133.000000),(384.000000 147.000000),(409.000000
133.000000),(419.000000 184.000000),(428.000000 193.000000);(39.000000
176.000000),(34.000000 200.000000),(40.000000 226.000000),(34.000000
247.000000),(36.000000 265.000000),(39.000000 292.000000),(36.000000
317.000000),(34.000000 344.000000),(30.000000 357.000000),(28.000000
374.000000),(27.000000 390.000000),(25.000000 422.000000),(23.000000
445.000000),(44.000000 456.000000),(65.000000 460.000000),(92.000000
461.000000),(124.000000 461.000000),(120.000000 442.000000),(121.000000
420.000000),(120.000000 400.000000),(115.000000 381.000000),(113.000000
350.000000),(109.000000 322.000000),(108.000000 305.000000),(111.000000
271.000000),(110.000000 249.000000),(111.000000 215.000000),(109.000000
181.000000),(108.000000 152.000000),(110.000000 197.000000),(40.000000
151.000000),(60.000000 136.000000),(85.000000 142.000000),(72.000000
421.000000),(72.000000 400.000000),(71.000000 371.000000),(73.000000
344.000000),(74.000000 203.000000),(73.000000 228.000000),(71.000000
264.000000);(9.000000 121.000000),(22.000000 120.000000),(38.000000
117.000000),(54.000000 116.000000),(67.000000 113.000000),(84.000000
113.000000),(98.000000 110.000000),(118.000000 106.000000),(132.000000
104.000000),(150.000000 102.000000),(168.000000 97.000000),(185.000000
95.000000),(275.000000 78.000000),(288.000000 75.000000),(300.000000
71.000000),(315.000000 65.000000),(327.000000 77.000000),(327.000000
93.000000),(329.000000 105.000000),(329.000000 116.000000),(330.000000
128.000000),(332.000000 140.000000),(343.000000 142.000000),(355.000000
144.000000),(369.000000 141.000000),(376.000000 123.000000),(391.000000
117.000000),(423.000000 97.000000),(406.000000 107.000000),(441.000000
82.000000),(453.000000 66.000000),(507.000000 104.000000),(526.000000
89.000000),(543.000000 78.000000),(558.000000 65.000000),(577.000000
54.000000),(581.000000 103.000000),(564.000000 93.000000),(515.000000
64.000000),(458.000000 106.000000).
\end{verbatim}


\includegraphics[width=7cm,angle=270]{impl/motion-1-d1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d10.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d10m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d10m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d1m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d1m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d2m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d2m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d3m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d3m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d5.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d5m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-1-d5m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d10.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d10m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d10m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d1m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d1m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d2m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d2m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d3m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d3m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d5.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d5m001M1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/motion-2-d5m001M3.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-f1-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-f1-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-f2-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t05-f1-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t05-f1-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t05-f2-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t05-f2-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t100-f1-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t100-f1-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t100-f2-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t100-f2-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t50-f1-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t50-f1-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t50-f2-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/pyramid-t50-f2-2.log.ps}

\includegraphics[width=7cm,angle=270]{impl/test-1.log.ps}

\includegraphics[width=7cm,angle=270]{impl/test-2.log.ps}

\end{document}
