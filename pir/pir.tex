% Fachstudie NEXUS "Personen im Raum"
% $Id: pir.tex,v 1.8 2005/02/10 16:47:45 garbeam Exp $

\documentclass{article}
\usepackage[german]{babel} 
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{url}

\begin{document}

\title{Fachstudie 'Personen im Raum'}
\author{Steffen Keul, Marcel Kilgus, Anselm Garbe\\
\small Universität Stuttgart, Institut für Informatik, Nexus Forschungsprojekt}

\maketitle
\thispagestyle{empty}

\begin{abstract}
In dieser Studie werden Algorithmen zur Bilderkennung von Personen im
Raum anhand von Receiver Operator Characteristic Curves
gegenübergestellt und abschliessend eine Empfehlung ausgesprochen.
\end{abstract}

%------------------------------------------------------------------------- 
\section{Einleitung}
% TODO: Hintergrund etc.


%------------------------------------------------------------------------- 
\section{Szenarien}

Untersucht wird die Bilderkennung von einer Person im Raum bei drei
unterschiedlichen Bidlkontrasteinstellungen der verwendeten
Kamera, Modell MOBOTIX M1, siehe auch \url{http://www.mobotix.com}.

\begin{figure}[h]
    \begin{center}
        \begin{tabular}{l|l}
        \textbf{Format:} & JPEG\\ \hline
        \textbf{Kompression:} & Standard\\ \hline
        \textbf{Auflösung (Pixel):} & 640x480\\ \hline
        \textbf{Automatischer Lichtfilter:} & aus\\ \hline
        \textbf{Rauschenunterdrückung:} & aus\\ \hline
        \textbf{Bildschärfe (-2..20):} & 0\\
        \end{tabular}
    {\small \caption{Feste Bildeigenschaften}}
    \end{center}
\end{figure}

\subsection{Bildkontrasteinstellungen}
Die drei im Szenario verwendeten Bildkontrasteinstellungen können grob
in {\it hoch}, {\it normal} und {\it niedrig} eingestuft werden.
Motivation für diese Wahl war die Vermutung, dass ein geringes
Farbspektrum (niedriger Kontrast)
bessere Erkennungsraten liefert, als ein hohes Farbspektrum.

\begin{figure}[h!]
    \begin{center}
        \begin{tabular}{l|l}
        \textbf{Helligkeit (-10..10):} & 5\\ \hline
        \textbf{Sättigung (-10..10):} & 5\\
        \end{tabular}
    {\small \caption{Hoher Bildkontrast}}
    \end{center}
\end{figure}

\begin{figure}[h!]
    \begin{center}
        \begin{tabular}{l|l}
        \textbf{Helligkeit (-10..10):} & 0\\ \hline
        \textbf{Sättigung (-10..10):} & 0\\
        \end{tabular}
    {\small \caption{Hoher Bildkontrast}}
    \end{center}
\end{figure}

\begin{figure}[h!]
    \begin{center}
        \begin{tabular}{l|l}
        \textbf{Helligkeit (-10..10):} & -5\\ \hline
        \textbf{Sättigung (-10..10):} & -5\\
        \end{tabular}
    {\small \caption{Hoher Bildkontrast}}
    \end{center}
\end{figure}


\subsection{Offene Fragen}

Die Bilderkennung von mehreren Personen im Raum sowie von keiner Person
wurde bis auf einzelne Feldversuche nicht genauer untersucht.
Anzunehmen ist, dass die Erkennungsrate von mehreren Personen im Raum
etwas höher liegt, als bei einer einzelnen Person im Raum.
Die Erkennungsrate von Personen im Raum, obwohl sich keine Person im
Raum aufhält, wird als sehr gering angenommen.

Die Entwickler von OpenCV bieten keine Beispiele für optische
Bewegungsflusserkennung an, so dass der Schluss naheliegt, dass die
vorhandenen Algorithmen entweder ungeeignet sind oder nie getestet
wurden.

%------------------------------------------------------------------------- 
\section{Algorithmen}

Mit Ausnahme eines selbst implementierten Algorithmus, sind alle anderen
Algorithmen in der OpenCV Bibliothek\cite{opencv} von Intel enthalten.
Zur Erkennung von Personen werden Algorithmen untersucht, die Bewegungen
zwischen zwei Bildern erkennen können. Signifikante Bewegungen gelten
als Bewegung von größeren Objekten, darunter sind Bewegungen von
Menschen inbegriffen.

\subsection{CalcOpticalFlowHS}
Dieser Algorithmus berechnet den optischen Bewegungsfluss für alle Pixel
zwischen zwei Bildern nach dem Horn \& Schunk \cite{Horn81} Verfahren.

\subsection{CalcOpticalFlowLK}
Dieser Algorithmus berechnet den optischen Bewegungsfluss für alle Pixel
zwischen zwei Bildern nach dem Lucas \& Kanade \cite{Lucas81} Verfahren.

\subsection{CalcOpticalFlowBM}
Dieser Algorithmus berechnet den optischen Bewegungsfluss für
Segmente einer frei definierbaren Größe zwischen zwei Bildern.
Um so gröber die Segmente gewählt werden, desto performanter arbeitet der
Algorithmus.

\subsection{CalcOpticalFlowPyrLK}
Dieser Algorithmus \cite{Bouget00} basiert auf einer iterativen Version der optischen
Fluss-Pyramiden nach Lucas \& Kanade. Er berechnet den optischen
Bewegungsfluss auf einer Menge von Punkten zwischen zwei Bildern. Es
werden Bewegungen mit Sub-Pixel Genauigkeit gefunden.

\subsection{SegmentMotion}
Dieser Algorithmus sucht alle bewegten Segmente zwischen zwei Bildern
und vergibt für jede Bewegung in einer Segmentmaske Werte zwischen
$1..N$, je nach Bewegungsintensität.

\subsection{Eigene Implementierung}

%------------------------------------------------------------------------- 
\section{Receiver Operator Characteristic Curves}

%------------------------------------------------------------------------- 
\section{Empfehlung}
Im Rahmen dieser Fachstudie empfehlen wir die optische Flusserkennung
nach \cite{KIL05}, die auch im Source Code im Anhang vorliegt.

\begin{thebibliography}{99}
\bibitem{KIL05} Marcel Kilgus, Optische Flusserkennung mit 15 LOC, 2005.
\bibitem{opencv} http://opencvlibrary.sf.net
\bibitem{Horn81} Berthold K. P. Horn und Brian G. Schunck. Determining
Optical Flow. Artificial Intelligence, 17, pp. 185-203, 1981.
\bibitem{Lucas81} Lucas, B. und Kanade, T. An Iterative Image
Registration Technique with an Application to Stereo Vision, Proc. of
7th International Joint Conference on Artificial Intelligence (IJCAI),
pp. 674-679.
\bibitem{Bouget00} Jean-Yves Bouguet. Pyramidal Implementation of the
Lucas Kanade Feature Tracker.
\end{thebibliography}

\end{document}
